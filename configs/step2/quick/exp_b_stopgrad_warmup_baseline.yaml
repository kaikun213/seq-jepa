# Experiment B Variant: Stop-Grad with Warmup + moderate Î»_rate (Baseline-Lite)
# Purpose: Test if LR warmup + moderate rate helps stability

run:
  name: step2-exp-b-stopgrad-warmup-baseline-lite
  seed: 42
  device: auto
  mps_fallback: true
  epochs: 10
  output_dir: runs/step2/exp-b-stopgrad-warmup-baseline-lite
  drop_last: true

dataset:
  name: cifar10_rot
  data_root: data
  seq_len: 3
  rotations: [0, 90, 180, 270]
  download: true
  subset_train: 20000
  subset_val: 2000
  subset_seed: 42
  batch_size: 128
  num_workers: 0

model:
  img_size: 32
  n_channels: 3
  ema: false                   # No EMA
  ema_decay: 0.996
  teacherless: true            # Use stop-grad
  pred_hidden: 1024
  num_heads: 4
  num_enc_layers: 3
  act_cond: 1
  learn_act_emb: 1
  act_latentdim: 2
  act_projdim: 128
  cifar_resnet: true
  sharpening_enabled: false
  symmetric: false

loss:
  rate_loss_enabled: true
  lambda_rate: 0.03            # 3x baseline (moderate)
  alpha: 1.0
  rate_target: agg_out
  rate_use_stable: false

optim:
  name: adam
  lr: 0.001
  weight_decay: 0.0
  probe_lr: 0.001
  scheduler: cosine            # Add cosine LR schedule
  warmup_epochs: 2             # 2 epoch warmup
  min_lr: 0.0001

eval:
  latent_type: rot
  eval_type: rot
  subspace_enabled: false
  subspace_frequency: 0
  subspace_viz: false

logging:
  wandb:
    enabled: true
    project: seq-jepa-streaming
    group: step2-exp-b-warmup
    mode: online

gating:
  linacc_test_min: 30.0
  r2_test_min: 0.1

