# Step 2 Exp B: Teacherless + Rate Loss (Remote Baseline)
# CIFAR-100, 30 epochs, validates teacherless training with rate regularization

run:
  name: step2-exp-b-teacherless-remote
  seed: 42
  device: auto
  epochs: 30
  output_dir: runs/remote/step2-exp-b-teacherless
  drop_last: true
  save_checkpoint: true

dataset:
  name: cifar100_aug
  data_root: data
  seq_len: 3
  download: true
  aug: true
  no_blur: false
  action_norm: true
  use_rel_latents: false
  subset_train: 50000
  subset_val: 10000
  subset_seed: 42
  batch_size: 512
  num_workers: 8

model:
  img_size: 32
  n_channels: 3
  ema: false
  ema_decay: 0.996
  teacherless: true
  pred_hidden: 1024
  num_heads: 4
  num_enc_layers: 3
  act_cond: 1
  learn_act_emb: 1
  act_latentdim: 9
  act_projdim: 128
  cifar_resnet: true

loss:
  rate_loss_enabled: true
  lambda_rate: 0.03   # Tuned for teacherless stability
  alpha: 1.0
  rate_target: agg_out

optim:
  name: adamw
  lr: 0.0004
  weight_decay: 0.001
  probe_lr: 0.001
  scheduler: cosine
  warmup_epochs: 5
  min_lr: 0.00001

eval:
  latent_type: aug
  eval_type: aug
  subspace_enabled: true
  subspace_frequency: 10

logging:
  wandb:
    enabled: true
    project: seq-jepa-streaming
    group: step2-remote
    mode: online

gating:
  linacc_test_min: 10.0
  r2_test_min: 0.1

